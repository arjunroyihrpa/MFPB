{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/philip/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/philip/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit as ss\n",
    "\n",
    "from DataPreprocessing.my_utils import get_fairness, get_score, vis\n",
    "from Maximus_optimized_non_dominated import Multi_Fair as maximus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier1(\n",
    "    X_train, X_test, y_train, y_test, sa_index, p_Group, base_learners, preference\n",
    "):\n",
    "\n",
    "    classifier = maximus(\n",
    "        n_estimators=base_learners,\n",
    "        saIndex=sa_index,\n",
    "        saValue=p_Group,\n",
    "        preference=preference,\n",
    "    )\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_probs = classifier.predict_proba(X_test)[:, 1]\n",
    "    y_pred_labels = classifier.predict(X_test)\n",
    "    f = classifier.feature_importances_\n",
    "    # return classifier.conf_scores, classifier.get_weights_over_iterations(), classifier.get_initial_weights()\n",
    "    return y_pred_probs, y_pred_labels, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y):\n",
    "    in_ts, pred1, fx = [], [], []\n",
    "    sss = ss(n_splits=5, test_size=0.4)\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        in_ts.append(test_index)\n",
    "        pb1, pd1, f1 = train_classifier1(\n",
    "            X_train, X_test, y_train, y_test, sa_index, p_Group, 499, [0.33, 0.34, 0.33]\n",
    "        )\n",
    "        pred1.append(pd1)\n",
    "        fx.append(f1)\n",
    "        print(f1.theta - 1, \" : \", f1.ob[f1.theta - 1])\n",
    "    return in_ts, pred1, fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45175\n",
      "Features we will be using for classification are: [\"workclass_' Federal-gov'\", \"workclass_' Local-gov'\", \"workclass_' Private'\", \"workclass_' Self-emp-inc'\", \"workclass_' Self-emp-not-inc'\", \"workclass_' State-gov'\", \"workclass_' Without-pay'\", \"education_' 10th'\", \"education_' 11th'\", \"education_' 12th'\", \"education_' 1st-4th'\", \"education_' 5th-6th'\", \"education_' 7th-8th'\", \"education_' 9th'\", \"education_' Assoc-acdm'\", \"education_' Assoc-voc'\", \"education_' Bachelors'\", \"education_' Doctorate'\", \"education_' HS-grad'\", \"education_' Masters'\", \"education_' Preschool'\", \"education_' Prof-school'\", \"education_' Some-college'\", \"Maritial-status_' Divorced'\", \"Maritial-status_' Married-AF-spouse'\", \"Maritial-status_' Married-civ-spouse'\", \"Maritial-status_' Married-spouse-absent'\", \"Maritial-status_' Never-married'\", \"Maritial-status_' Separated'\", \"Maritial-status_' Widowed'\", \"occupation_' Adm-clerical'\", \"occupation_' Armed-Forces'\", \"occupation_' Craft-repair'\", \"occupation_' Exec-managerial'\", \"occupation_' Farming-fishing'\", \"occupation_' Handlers-cleaners'\", \"occupation_' Machine-op-inspct'\", \"occupation_' Other-service'\", \"occupation_' Priv-house-serv'\", \"occupation_' Prof-specialty'\", \"occupation_' Protective-serv'\", \"occupation_' Sales'\", \"occupation_' Tech-support'\", \"occupation_' Transport-moving'\", 'race', 'sex', \"country_' Cambodia'\", \"country_' Canada'\", \"country_' China'\", \"country_' Columbia'\", \"country_' Cuba'\", \"country_' Dominican-Republic'\", \"country_' Ecuador'\", \"country_' El-Salvador'\", \"country_' England'\", \"country_' France'\", \"country_' Germany'\", \"country_' Greece'\", \"country_' Guatemala'\", \"country_' Haiti'\", \"country_' Holand-Netherlands'\", \"country_' Honduras'\", \"country_' Hong'\", \"country_' Hungary'\", \"country_' India'\", \"country_' Iran'\", \"country_' Ireland'\", \"country_' Italy'\", \"country_' Jamaica'\", \"country_' Japan'\", \"country_' Laos'\", \"country_' Mexico'\", \"country_' Nicaragua'\", \"country_' Outlying-US(Guam-USVI-etc)'\", \"country_' Peru'\", \"country_' Philippines'\", \"country_' Poland'\", \"country_' Portugal'\", \"country_' Puerto-Rico'\", \"country_' Scotland'\", \"country_' South'\", \"country_' Taiwan'\", \"country_' Thailand'\", \"country_' Trinadad&Tobago'\", \"country_' United-States'\", \"country_' Vietnam'\", \"country_' Yugoslavia'\", 'age', 'Capital-gain', 'Capital-loss', 'Hours-per-week', 'Hours-per-week', 'Hours-per-week'] \n",
      "\n",
      "54  :  [0.17833333 0.30881885 0.10972222]\n",
      "474  :  [0.135      0.15313023 0.07980226]\n",
      "368  :  [0.17       0.16271383 0.04145597]\n",
      "475  :  [0.13666667 0.16741575 0.0424277 ]\n",
      "104  :  [0.18166667 0.01378767 0.02982163]\n",
      "\n",
      "\n",
      "For Sensitive attribute index  44\n",
      "avg_TPR_unprot: 0.6558774766067742 avg_TPR_prot: 0.565\n",
      "avg_TNR_unprot: 0.843262273453391 avg_TNR_prot: 0.919513236856462\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "For Sensitive attribute index  45\n",
      "avg_TPR_unprot: 0.645248323486137 avg_TPR_prot: 0.6532532311170082\n",
      "avg_TNR_unprot: 0.8364811107632756 avg_TNR_prot: 0.8966600753820819\n",
      "\n",
      "-------------------------------------------\n",
      "\n",
      "avg_TPR: 0.6482142857142857 avg_TNR: 0.8569444444444445\n",
      "avg_acc: 0.7985 avg_Bacc: 0.7525793650793651\n",
      "avg_auc: 0.7525793650793652 avg_GM: 0.743402614957823\n"
     ]
    }
   ],
   "source": [
    "results, performance, Hx = [], [], []\n",
    "for dt in [\"Adult\"]:\n",
    "    if dt == \"Adult\":\n",
    "        from DataPreprocessing.load_adult import load_adult\n",
    "\n",
    "        X, y, sa_index, p_Group, x_control, F = load_adult()\n",
    "        how_many = 1000\n",
    "        X = X[:how_many, :]\n",
    "        y = y[:how_many]\n",
    "        x_control[\"race\"] = x_control[\"race\"][:how_many]\n",
    "        x_control[\"sex\"] = x_control[\"sex\"][:how_many]\n",
    "        # v='Adult_2_sensi_Mari_Sex'\n",
    "        saf = sa_index[1]\n",
    "    elif dt == \"Bank\":\n",
    "        from DataPreprocessing.load_bank import load_bank\n",
    "\n",
    "        X, y, sa_index, p_Group, x_control, F = load_bank()\n",
    "        saf = sa_index[0]\n",
    "        print(saf)\n",
    "    elif dt == \"Credit\":\n",
    "        from DataPreprocessing.load_credit import load_credit\n",
    "\n",
    "        X, y, sa_index, p_Group, x_control, F = load_credit()\n",
    "        saf = sa_index[0]\n",
    "    elif dt == \"Compas\":\n",
    "        from DataPreprocessing.load_compas_data import load_compas\n",
    "\n",
    "        X, y, sa, p_G, x_control, F = load_compas()\n",
    "        sa_index = [sa[-1], sa[0]]\n",
    "        p_Group = [p_G[-1], p_G[0]]\n",
    "    sensitives = [F[v] for v in sa_index]\n",
    "    in_ts, pred1, f1 = train(X, y)\n",
    "    results.append(list(get_fairness(sa_index, p_Group, in_ts, pred1, X, y).values()))\n",
    "    performance.append(get_score(pred1, in_ts, X, y))\n",
    "    Hx.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.33, 0.34, 0.33]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hx[0][0].preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selection import PreferenceSurvival\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_values = np.row_stack(Hx[0][0].PF.values())\n",
    "preference_vectors = np.array(Hx[0][0].preference).reshape(1,-1)\n",
    "# Add more for testing\n",
    "preference_vectors = np.row_stack([[0,0.8,0.2], [1.0,0,0], [0,0.5,0.5], preference_vectors])\n",
    "solutions = Hx[0][0].ob\n",
    "\n",
    "max_solutions = len(solutions)\n",
    "optimal_solution_set = PreferenceSurvival(preference_vectors).do(solutions, objective_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/500 final solutions with respect to the 4 reference vector\n"
     ]
    }
   ],
   "source": [
    "print(f\"{optimal_solution_set.shape[0]}/{max_solutions} final solutions with respect to the {len(preference_vectors)} reference vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.8 , 0.2 ],\n",
       "       [1.  , 0.  , 0.  ],\n",
       "       [0.  , 0.5 , 0.5 ],\n",
       "       [0.33, 0.34, 0.33]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preference_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23833333, 0.85628743, 0.06180556],\n",
       "       [0.23333333, 0.83832335, 0.07575758],\n",
       "       [0.23333333, 0.83832335, 0.07575758],\n",
       "       [0.19      , 0.64114727, 0.11157407]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_solution_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19      , 0.64114727, 0.11157407],\n",
       "       [0.23333333, 0.83832335, 0.07575758],\n",
       "       [0.23833333, 0.85628743, 0.06180556]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(optimal_solution_set, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
